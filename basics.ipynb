{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "898be185dfe64ad3",
   "metadata": {},
   "source": [
    "First, let's import necessary libraries and prepare a toy dataset. In a real scenario, you would fetch content feature vectors for users and items from your MongoDB. Here, we'll simulate this with small numpy arrays. Each user and item is represented by a feature vector (e.g., encoding topics of interest for users and content topics for courses). We also define a set of user-item interactions (edges in the graph). This toy data will allow us to demonstrate the model pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d3ca0239ddb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision matplotlib networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26839e8814bb054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8303d71957f485de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Sample data parameters\n",
    "num_users = 5\n",
    "num_items = 10\n",
    "feature_dim = 3   # Dimension of content feature vectors for users/items (example)\n",
    "\n",
    "# Example content-based feature vectors for each user (e.g., preference scores for 3 topics)\n",
    "user_content = np.array([\n",
    "    [1.0, 0.2, 0.1],   # User 0: strong in topic0\n",
    "    [0.1, 0.9, 0.2],   # User 1: strong in topic1\n",
    "    [0.7, 0.7, 0.1],   # User 2: interest in topic0 & topic1\n",
    "    [0.0, 0.1, 0.9],   # User 3: strong in topic2\n",
    "    [0.2, 0.8, 0.8]    # User 4: interest in topic1 & topic2\n",
    "])\n",
    "\n",
    "# Example content-based feature vectors for each item (e.g., content distribution over 3 topics)\n",
    "item_content = np.array([\n",
    "    [1.0, 0.0, 0.0],    # Item 0: pure topic0 content\n",
    "    [0.8, 0.2, 0.0],    # Item 1: mostly topic0\n",
    "    [0.0, 1.0, 0.0],    # Item 2: pure topic1 content\n",
    "    [0.1, 0.9, 0.0],    # Item 3: mostly topic1\n",
    "    [0.0, 0.0, 1.0],    # Item 4: pure topic2 content\n",
    "    [0.0, 0.4, 0.8],    # Item 5: mostly topic2\n",
    "    [0.6, 0.6, 0.0],    # Item 6: mixed topic0 & topic1\n",
    "    [0.0, 0.7, 0.7],    # Item 7: mixed topic1 & topic2\n",
    "    [0.5, 0.0, 0.5],    # Item 8: mixed topic0 & topic2\n",
    "    [0.33, 0.33, 0.33]  # Item 9: balanced across all topics\n",
    "])\n",
    "\n",
    "# Define user-item interactions (edges in the bipartite graph)\n",
    "# Each tuple (u, i) means user u has interacted with item i (e.g., viewed or liked the course)\n",
    "interactions = [\n",
    "    (0, 0), (0, 1),        # User 0 interacted with Item 0 and 1\n",
    "    (1, 2), (1, 3),        # User 1 with Item 2 and 3\n",
    "    (2, 0), (2, 2), (2, 6),# User 2 with Item 0, 2, 6\n",
    "    (3, 4), (3, 5),        # User 3 with Item 4, 5\n",
    "    (4, 3), (4, 5), (4, 7) # User 4 with Item 3, 5, 7\n",
    "]\n",
    "\n",
    "# Build neighbor lists (adjacency) for each user and item, for graph propagation\n",
    "user_neighbors = {u: [] for u in range(num_users)}\n",
    "item_neighbors = {i: [] for i in range(num_items)}\n",
    "for (u, i) in interactions:\n",
    "    user_neighbors[u].append(i)\n",
    "    item_neighbors[i].append(u)\n",
    "\n",
    "# Degree (number of neighbors) for normalization in GCN propagation\n",
    "deg_user = {u: len(user_neighbors[u]) for u in user_neighbors}\n",
    "deg_item = {i: len(item_neighbors[i]) for i in item_neighbors}\n",
    "\n",
    "# Move data to PyTorch (the embedding initialization will handle conversion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5a6d02a12e615",
   "metadata": {},
   "source": [
    "Next, let's visualize the user-item interaction graph to understand the structure. We create a bipartite graph where one set of nodes are users (U0–U4) and the other set are items (I0–I9), with edges showing interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7fef780b583f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the bipartite user-item graph\n",
    "G = nx.Graph()\n",
    "# Add user nodes and item nodes\n",
    "user_nodes = [f\"U{u}\" for u in range(num_users)]\n",
    "item_nodes = [f\"I{i}\" for i in range(num_items)]\n",
    "G.add_nodes_from(user_nodes, bipartite=0)\n",
    "G.add_nodes_from(item_nodes, bipartite=1)\n",
    "# Add edges between users and items\n",
    "for (u, i) in interactions:\n",
    "    G.add_edge(f\"U{u}\", f\"I{i}\")\n",
    "\n",
    "# Compute positions for a bipartite layout (users on left, items on right)\n",
    "pos = {}\n",
    "# Users at x = 0\n",
    "for idx, u in enumerate(user_nodes):\n",
    "    pos[u] = (-1.0, idx)  # spread out vertically\n",
    "# Items at x = 1\n",
    "for idx, i in enumerate(item_nodes):\n",
    "    pos[i] = (1.0, idx)\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(6, 4))\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=user_nodes, node_color='lightblue', node_shape='s', label='Users')\n",
    "nx.draw_networkx_nodes(G, pos, nodelist=item_nodes, node_color='lightgreen', node_shape='o', label='Items')\n",
    "nx.draw_networkx_edges(G, pos, edge_color='gray')\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "plt.axis('off')\n",
    "plt.title(\"User-Item Interaction Graph\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7a033260c77169",
   "metadata": {},
   "source": [
    "User-item bipartite graph visualization. In this graph, squares represent users U0–U4 and circles represent items I0–I9. An edge between a user and an item means that user interacted with that item (e.g., a user viewed or liked a course). Such a graph is the basis for graph-based collaborative filtering models like LightGCN.\n",
    "In the code above: We used NetworkX to draw the graph. The users are laid out on the left (x = -1) and items on the right (x = 1) for clarity. This structure shows how information will flow in the GNN: user nodes aggregate messages from their item neighbors, and item nodes aggregate messages from their user neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4309f556fe7ce3",
   "metadata": {},
   "source": [
    "## LightGCN Model Definition\n",
    "Now, we'll define the LightGCN model. LightGCN is a simplified Graph Convolutional Network for recommendations that only uses neighborhood aggregation and omits feature transformations and nonlinear activations\n",
    "medium.com\n",
    "medium.com\n",
    ". It learns embeddings for users and items by propagating information on the user-item interaction graph. Importantly, we will integrate content-based features by initializing the node embeddings with the given feature vectors (instead of random initializations). Key points of LightGCN:\n",
    "Each user and item has an embedding vector that is updated through multiple propagation layers.\n",
    "In each layer, a node's embedding is updated as the average of its neighbors' embeddings from the previous layer (with a normalization factor)\n",
    "medium.com\n",
    ".\n",
    "The final embedding for a node is the sum (or average) of its embedding from each layer (including the initial layer)\n",
    "medium.com\n",
    ".\n",
    "The model predicts the affinity of a user for an item via the inner product of their final embeddings\n",
    "medium.com\n",
    ".\n",
    "Let's implement this step by step in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463dd345c5cf8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embed_dim, num_layers, user_features=None, item_features=None):\n",
    "        \"\"\"\n",
    "        LightGCN model initialization.\n",
    "        - num_users, num_items: number of user and item nodes.\n",
    "        - embed_dim: embedding vector dimension.\n",
    "        - num_layers: number of propagation layers in GCN.\n",
    "        - user_features, item_features: optional initial features for users and items (numpy arrays).\n",
    "        \"\"\"\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define trainable embeddings for users and items.\n",
    "        # If content features are provided and match embed_dim, use them as initial embeddings.\n",
    "        if user_features is not None and user_features.shape[1] == embed_dim:\n",
    "            self.user_embedding = nn.Embedding(num_users, embed_dim)\n",
    "            # Initialize user embedding weights from provided features\n",
    "            self.user_embedding.weight.data = torch.tensor(user_features, dtype=torch.float32)\n",
    "        else:\n",
    "            # If no features provided (or dimensionality mismatch), initialize randomly\n",
    "            self.user_embedding = nn.Embedding(num_users, embed_dim)\n",
    "            nn.init.xavier_uniform_(self.user_embedding.weight)  # Xavier initialization for embeddings\n",
    "\n",
    "        if item_features is not None and item_features.shape[1] == embed_dim:\n",
    "            self.item_embedding = nn.Embedding(num_items, embed_dim)\n",
    "            self.item_embedding.weight.data = torch.tensor(item_features, dtype=torch.float32)\n",
    "        else:\n",
    "            self.item_embedding = nn.Embedding(num_items, embed_dim)\n",
    "            nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "\n",
    "    def propagate(self, user_neighbors, item_neighbors, deg_user, deg_item):\n",
    "        \"\"\"\n",
    "        Perform K-layer propagation to compute final embeddings for all users and items.\n",
    "        - user_neighbors, item_neighbors: dictionaries of adjacency lists.\n",
    "        - deg_user, deg_item: dictionaries of node degrees for normalization.\n",
    "        Returns:\n",
    "        - user_emb_final, item_emb_final: final embeddings after K propagation layers.\n",
    "        \"\"\"\n",
    "        # Initial embeddings (layer 0)\n",
    "        user_emb = self.user_embedding.weight    # shape: [num_users, embed_dim]\n",
    "        item_emb = self.item_embedding.weight    # shape: [num_items, embed_dim]\n",
    "\n",
    "        # Store embeddings at each layer (including initial)\n",
    "        user_emb_layers = [user_emb]\n",
    "        item_emb_layers = [item_emb]\n",
    "\n",
    "        # Neighborhood aggregation for each layer\n",
    "        for layer in range(1, self.num_layers + 1):\n",
    "            # New containers for this layer's embeddings\n",
    "            new_user_emb = torch.zeros_like(user_emb)\n",
    "            new_item_emb = torch.zeros_like(item_emb)\n",
    "            prev_user_emb = user_emb_layers[-1]  # user embeddings from previous layer\n",
    "            prev_item_emb = item_emb_layers[-1]  # item embeddings from previous layer\n",
    "\n",
    "            # Aggregate neighbor embeddings for each user\n",
    "            for u in range(self.num_users):\n",
    "                if len(user_neighbors[u]) == 0:\n",
    "                    # If a user has no neighbors (no interactions), skip (remains zero)\n",
    "                    continue\n",
    "                # Sum the embeddings of all neighbor items (from prev layer)\n",
    "                # using normalized weight 1/sqrt(deg(u) * deg(item))\n",
    "                total = torch.zeros(self.embed_dim, device=user_emb.device)\n",
    "                for i in user_neighbors[u]:\n",
    "                    norm_factor = (deg_user[u] * deg_item[i]) ** 0.5  # sqrt(|N(u)| * |N(i)|)\n",
    "                    total += prev_item_emb[i] / norm_factor\n",
    "                new_user_emb[u] = total\n",
    "\n",
    "            # Aggregate neighbor embeddings for each item\n",
    "            for i in range(self.num_items):\n",
    "                if len(item_neighbors[i]) == 0:\n",
    "                    continue\n",
    "                total = torch.zeros(self.embed_dim, device=user_emb.device)\n",
    "                for u in item_neighbors[i]:\n",
    "                    norm_factor = (deg_user[u] * deg_item[i]) ** 0.5\n",
    "                    total += prev_user_emb[u] / norm_factor\n",
    "                new_item_emb[i] = total\n",
    "\n",
    "            # Append this layer's embeddings to the list\n",
    "            user_emb_layers.append(new_user_emb)\n",
    "            item_emb_layers.append(new_item_emb)\n",
    "\n",
    "        # Combine embeddings from all layers (including initial layer 0).\n",
    "        # LightGCN typically sums the embeddings from each layer:contentReference[oaicite:6]{index=6}.\n",
    "        user_emb_final = torch.zeros_like(user_emb)\n",
    "        item_emb_final = torch.zeros_like(item_emb)\n",
    "        for emb in user_emb_layers:\n",
    "            user_emb_final += emb\n",
    "        for emb in item_emb_layers:\n",
    "            item_emb_final += emb\n",
    "        # (Optionally, could divide by (num_layers+1) to take an average; here sum is fine or average equivalently)\n",
    "\n",
    "        return user_emb_final, item_emb_final\n",
    "\n",
    "    def forward(self, user_indices, item_indices, user_neighbors, item_neighbors, deg_user, deg_item):\n",
    "        \"\"\"\n",
    "        Forward pass to predict scores for given user-item pairs.\n",
    "        - user_indices, item_indices: tensors of indices for users and items to score.\n",
    "        Returns:\n",
    "        - scores: tensor of predicted scores for each (user, item) pair.\n",
    "        \"\"\"\n",
    "        # Get final embeddings after propagation\n",
    "        user_emb_final, item_emb_final = self.propagate(user_neighbors, item_neighbors, deg_user, deg_item)\n",
    "        # Select the embeddings for the specified user and item indices\n",
    "        u_emb = user_emb_final[user_indices]    # shape: [batch_size, embed_dim]\n",
    "        i_emb = item_emb_final[item_indices]    # shape: [batch_size, embed_dim]\n",
    "        # Compute dot-product similarity for each pair (this is the predicted score)\n",
    "        scores = torch.sum(u_emb * i_emb, dim=1)  # inner product along embedding dimension\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c762904b132f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the LightGCN model\n",
    "embed_dim = feature_dim  # we'll use the same dimension as our feature vectors for embedding\n",
    "num_layers = 2           # number of propagation layers in GCN\n",
    "model = LightGCN(num_users, num_items, embed_dim, num_layers, user_features=user_content, item_features=item_content)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326c99264d8b1557",
   "metadata": {},
   "source": [
    "## Training the LightGCN Model\n",
    "We will train the model using Bayesian Personalized Ranking (BPR) loss, which is a common objective for implicit feedback recommenders like ours. BPR loss encourages the model to score observed (user, item) pairs higher than unobserved pairs. In practice, for each known interaction (positive example), we sample a random item that the user has not interacted with (negative example), and train the model to rank the positive item higher than the negative. We also include L2 regularization on the embedding parameters to prevent overfitting.\n",
    "\n",
    "Let's set up the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee32d91643eb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer for gradient descent\n",
    "num_epochs = 50\n",
    "reg_lambda = 1e-4  # regularization strength\n",
    "\n",
    "# Prepare for training\n",
    "model.train()  # set model to training mode\n",
    "epoch_losses = []  # to record the training loss each epoch\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    total_loss = 0.0\n",
    "    count = 0\n",
    "    # Shuffle interactions for each epoch (stochastic order)\n",
    "    np.random.shuffle(interactions)\n",
    "    for (u, i) in interactions:\n",
    "        # Skip if a user has no negative candidate (not likely in real data unless user interacted with all items)\n",
    "        if len(user_neighbors[u]) == num_items:\n",
    "            continue\n",
    "        # Sample a negative item (j) that user u has NOT interacted with\n",
    "        j = np.random.randint(0, num_items)\n",
    "        while j in user_neighbors[u]:\n",
    "            j = np.random.randint(0, num_items)\n",
    "        # Create tensors for the user and item indices\n",
    "        # We'll score (u,i) as positive and (u,j) as negative in one forward pass by duplicating u\n",
    "        user_idx = torch.tensor([u, u], dtype=torch.long, device=device)\n",
    "        item_idx = torch.tensor([i, j], dtype=torch.long, device=device)\n",
    "\n",
    "        # Forward pass: get scores for (u,i) and (u,j)\n",
    "        optimizer.zero_grad()              # reset gradients from previous step\n",
    "        scores = model(user_idx, item_idx, user_neighbors, item_neighbors, deg_user, deg_item)\n",
    "        # scores is a tensor of length 2: [score(u,i), score(u,j)]\n",
    "        score_pos = scores[0]\n",
    "        score_neg = scores[1]\n",
    "\n",
    "        # Compute BPR loss: -log(sigmoid(score_pos - score_neg))\n",
    "        diff = score_pos - score_neg\n",
    "        loss = -torch.log(torch.sigmoid(diff) + 1e-8)  # add a small constant to avoid log(0)\n",
    "        loss = loss + 0.0  # convert from tensor to scalar (for autograd, it's fine as is)\n",
    "\n",
    "        # Add L2 regularization on user and item embeddings (to discourage large weights)\n",
    "        reg_loss = reg_lambda * (model.user_embedding.weight.norm(2).pow(2) +\n",
    "                                 model.item_embedding.weight.norm(2).pow(2))\n",
    "        total_batch_loss = loss + reg_loss\n",
    "\n",
    "        # Backpropagation\n",
    "        total_batch_loss.backward()  # compute gradients\n",
    "        optimizer.step()             # update model parameters\n",
    "\n",
    "        total_loss += loss.item()    # accumulate the BPR loss (for monitoring)\n",
    "        count += 1\n",
    "\n",
    "    # Record average loss for this epoch\n",
    "    avg_loss = total_loss / (count if count > 0 else 1)\n",
    "    epoch_losses.append(avg_loss)\n",
    "    # Print progress occasionally\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch}/{num_epochs}, average BPR loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382720fefbe68e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training loss curve\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1, len(epoch_losses)+1), epoch_losses, marker='o')\n",
    "plt.title(\"Training Loss Curve (BPR loss)\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Average BPR Loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45426d44f67f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to evaluation mode for inference\n",
    "model.eval()\n",
    "\n",
    "# Get final embeddings for all users and items after training\n",
    "user_emb_final, item_emb_final = model.propagate(user_neighbors, item_neighbors, deg_user, deg_item)\n",
    "user_emb_final = user_emb_final.cpu().detach().numpy()\n",
    "item_emb_final = item_emb_final.cpu().detach().numpy()\n",
    "\n",
    "# Use PCA to reduce embedding dimension to 2 for visualization\n",
    "from sklearn.decomposition import PCA\n",
    "all_emb = np.vstack([user_emb_final, item_emb_final])  # combine user and item embeddings\n",
    "if all_emb.shape[1] > 2:\n",
    "    # Fit PCA on all embeddings and transform\n",
    "    emb_2d = PCA(n_components=2).fit_transform(all_emb)\n",
    "else:\n",
    "    # If embeddings are already 2D or 1D, we can pad or take them as is\n",
    "    if all_emb.shape[1] == 1:\n",
    "        emb_2d = np.hstack([all_emb, all_emb])  # duplicate the single dimension\n",
    "    else:\n",
    "        emb_2d = all_emb\n",
    "\n",
    "# Split back into user and item embeddings\n",
    "user_emb_2d = emb_2d[:num_users]\n",
    "item_emb_2d = emb_2d[num_users:]\n",
    "\n",
    "# Plot the 2D embeddings\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(user_emb_2d[:,0], user_emb_2d[:,1], c='blue', label='Users')\n",
    "plt.scatter(item_emb_2d[:,0], item_emb_2d[:,1], c='green', label='Items')\n",
    "# Annotate points with their IDs (U0, I0, etc.)\n",
    "for u_idx in range(num_users):\n",
    "    plt.annotate(f\"U{u_idx}\", (user_emb_2d[u_idx,0], user_emb_2d[u_idx,1]), color='blue')\n",
    "for i_idx in range(num_items):\n",
    "    plt.annotate(f\"I{i_idx}\", (item_emb_2d[i_idx,0], item_emb_2d[i_idx,1]), color='green')\n",
    "plt.title(\"User and Item Embeddings in 2D Space\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc850f13e7cfe773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get top-N recommendations for a given user\n",
    "def recommend_for_user(user_id, N=3):\n",
    "    model.eval()\n",
    "    # Get all item scores for this user\n",
    "    user_indices = torch.tensor([user_id] * num_items, device=device)\n",
    "    item_indices = torch.tensor(list(range(num_items)), device=device)\n",
    "    with torch.no_grad():  # no gradient needed for inference\n",
    "        scores = model(user_indices, item_indices, user_neighbors, item_neighbors, deg_user, deg_item)\n",
    "    scores = scores.cpu().numpy()\n",
    "    # Get top N item indices with highest scores that the user hasn't interacted with\n",
    "    ranked_items = np.argsort(-scores)\n",
    "    recommended = [item for item in ranked_items if item not in user_neighbors[user_id]][:N]\n",
    "\n",
    "    return recommended, scores\n",
    "\n",
    "# Example: recommendations for User 2\n",
    "user_id = 2\n",
    "topN = num_items\n",
    "rec_items, all_item_scores = recommend_for_user(user_id, N=topN)\n",
    "print(f\"Top {topN} recommended items for User {user_id}: {rec_items[:3]}\")\n",
    "recommended_item_scores = [all_item_scores[item_id] for item_id in rec_items]\n",
    "\n",
    "# Convert scores to probabilities using softmax\n",
    "# softmax(x_i) = exp(x_i) / sum(exp(x_j) for j in all_items)\n",
    "# We apply softmax only to the recommended items' scores to get their relative probabilities\n",
    "# among themselves. If you want the probability relative to *all* items, let me know.\n",
    "exp_scores = np.exp(recommended_item_scores - np.max(recommended_item_scores)) # Subtract max for numerical stability\n",
    "probabilities = exp_scores / np.sum(exp_scores)\n",
    "\n",
    "# Convert probabilities to percentages\n",
    "percentages = probabilities * 100\n",
    "\n",
    "print(\"Recommended Items with Probability Strength:\")\n",
    "for i, item_id in enumerate(rec_items):\n",
    "    print(f\"Item {item_id}: {percentages[i]:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
